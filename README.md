# ðŸ¤– AI Companion

A locally running AI assistant that remembers things about you, talks in different personalities, and runs commands on your system. Everything stays on your machine.

## Quick Start

### Prerequisites

1. **Node.js** (v18+)
2. **Ollama** â€” Install from [ollama.ai](https://ollama.ai)

### Setup

```bash
# 1. Pull a model (pick one)
ollama pull llama3.2          # 3B â€” fast, good for conversation
ollama pull llama3.1          # 8B â€” smarter, needs more RAM
ollama pull mistral           # 7B â€” good alternative

# 2. Install dependencies
cd ai-companion
npm install

# 3. Run
npm start
# or with file watching for dev:
npm run dev
```

Open **http://localhost:3000** and start chatting.

### Environment Variables

```bash
PORT=3000                                # Server port
OLLAMA_URL=http://localhost:11434        # Ollama API endpoint
MODEL=llama3.2                           # Model name (must be pulled in Ollama)
```

Example with a different model:
```bash
MODEL=mistral npm start
```

## Architecture

```
ai-companion/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ index.js          # Express + WebSocket server, Ollama integration
â”‚   â”œâ”€â”€ memory.js         # SQLite memory manager (conversations, facts, search)
â”‚   â””â”€â”€ commands.js       # Whitelist-based system command executor
â”œâ”€â”€ personalities/
â”‚   â””â”€â”€ profiles.json     # Personality definitions (system prompts, styles)
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html        # Cyberpunk terminal chat UI (single file)
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ companion.db      # SQLite database (auto-created)
â””â”€â”€ package.json
```

## Features

### Personalities
Switch between modes that change the AI's system prompt, temperature, and UI theme:
- ðŸ¤– **Default** â€” Helpful and conversational
- ðŸ˜ **Sarcastic** â€” Dry wit, playful roasts
- ðŸ˜ˆ **Evil Genius** â€” Bond villain energy
- âš¡ **Anime Mentor** â€” Everything is a training arc
- ðŸ˜´ **Sleepy** â€” Drowsy but insightful
- ðŸ”® **Netrunner** â€” Cyberpunk street runner

### Memory System
- **Explicit saves**: Say "remember that I like coffee" and it's stored
- **Auto-detection**: Preferences and facts are silently captured
- **Context injection**: Relevant memories are pulled into each conversation
- **Persistent**: Memories survive across sessions (stored in SQLite)

### System Commands
The AI can execute whitelisted commands when you ask:
- `open_browser` â€” Opens a URL
- `open_app` â€” Opens allowed apps (file manager, terminal, calculator, etc.)
- `play_music` â€” Searches YouTube for music
- `set_reminder` â€” Logs a reminder
- `system_info` â€” Shows system stats
- `run_shell` â€” Runs safe shell commands (date, whoami, etc.)

### Streaming
Responses stream token-by-token via WebSocket for a responsive feel.

## Extending

### Add a personality
Edit `personalities/profiles.json` and add a new entry:
```json
"pirate": {
  "name": "Pirate",
  "icon": "ðŸ´â€â˜ ï¸",
  "temperature": 0.85,
  "system_prompt": "You are a pirate AI. Speak like a sea dog...",
  "greeting": "Ahoy! What be yer query?",
  "style": { "accent_color": "#ff8800", "glow_intensity": 1.3 }
}
```

### Add a command
Edit `server/commands.js` and add to `COMMAND_HANDLERS`:
```js
my_command: async (params) => {
  // do something
  return { success: true, result: 'Done!' };
}
```

### Upgrade memory to vector search
Replace SQLite keyword search with `sqlite-vec` for semantic search:
1. `npm install sqlite-vec`
2. Generate embeddings via Ollama's `/api/embed` endpoint
3. Store embeddings alongside memories
4. Use cosine similarity for retrieval

## Roadmap

- [ ] Voice input (whisper.cpp)
- [ ] Voice output (Piper TTS)
- [ ] Proactive reminders / notifications
- [ ] Daily conversation summaries
- [ ] Vector search for memories
- [ ] Electron desktop wrapper
- [ ] Mood drift system
- [ ] Local file search assistant
